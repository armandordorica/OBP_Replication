{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa99daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obp.dataset import OpenBanditDataset\n",
    "from obp.policy import BernoulliTS\n",
    "from obp.ope import OffPolicyEvaluation, InverseProbabilityWeighting as IPW, SelfNormalizedInverseProbabilityWeighting as SNIPW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9b38f",
   "metadata": {},
   "source": [
    "# 1) Load Random/all logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c7c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obp.dataset.real:When `data_path` is not given, this class downloads the small-sized version of Open Bandit Dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Random/all: rounds=10,000, n_actions=80, len_list=3\n"
     ]
    }
   ],
   "source": [
    "SEED = 123\n",
    "\n",
    "\n",
    "ds = OpenBanditDataset(behavior_policy=\"random\", campaign=\"all\")\n",
    "bf = ds.obtain_batch_bandit_feedback()\n",
    "n = bf[\"n_rounds\"]\n",
    "print(f\"Loaded Random/all: rounds={n:,}, n_actions={bf['n_actions']}, len_list={ds.len_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e58d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_rounds', 'n_actions', 'action', 'position', 'reward', 'pscore', 'context', 'action_context'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3307a2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81917f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -4.99171626e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -5.43775368e-01],\n",
       "       [ 1.00000000e+00,  1.20000000e+01,  1.00000000e+00,\n",
       "         9.72751855e-01],\n",
       "       [ 2.00000000e+00,  1.50000000e+01,  6.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 1.00000000e+01,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.90943043e+00],\n",
       "       [ 2.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -4.99171626e-01],\n",
       "       [ 5.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "         3.48299469e-01],\n",
       "       [ 8.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -2.76152917e-01],\n",
       "       [ 2.00000000e+00,  1.80000000e+01,  4.00000000e+00,\n",
       "        -6.55284723e-01],\n",
       "       [ 5.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -3.87662271e-01],\n",
       "       [ 1.00000000e+01,  1.10000000e+01,  4.00000000e+00,\n",
       "         3.48299469e-01],\n",
       "       [ 5.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "         1.90943043e+00],\n",
       "       [ 1.00000000e+01,  1.20000000e+01,  1.00000000e+00,\n",
       "         3.15833521e+00],\n",
       "       [ 1.00000000e+01,  5.00000000e+00,  1.00000000e+00,\n",
       "         1.59720424e+00],\n",
       "       [ 2.00000000e+00,  1.20000000e+01,  1.00000000e+00,\n",
       "         1.44109114e+00],\n",
       "       [ 2.00000000e+00,  1.20000000e+01,  1.00000000e+00,\n",
       "         1.84252482e+00],\n",
       "       [ 5.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "         6.60525662e-01],\n",
       "       [ 5.00000000e+00,  1.60000000e+01,  1.00000000e+00,\n",
       "         1.44109114e+00],\n",
       "       [ 2.00000000e+00,  1.60000000e+01,  1.00000000e+00,\n",
       "         8.38940630e-01],\n",
       "       [ 2.00000000e+00,  6.00000000e+00,  4.00000000e+00,\n",
       "        -8.33699690e-01],\n",
       "       [ 5.00000000e+00,  8.00000000e+00,  6.00000000e+00,\n",
       "        -1.86945433e-01],\n",
       "       [ 5.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -4.09964142e-01],\n",
       "       [ 2.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 1.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -7.44492206e-01],\n",
       "       [ 1.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -5.88379110e-01],\n",
       "       [ 1.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 2.00000000e+00,  1.50000000e+01,  6.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 0.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 1.10000000e+01,  1.30000000e+01,  1.00000000e+00,\n",
       "        -3.87662271e-01],\n",
       "       [ 7.00000000e+00,  5.00000000e+00,  1.00000000e+00,\n",
       "         6.38223791e-01],\n",
       "       [ 5.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -1.20039820e-01],\n",
       "       [ 5.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -2.76152917e-01],\n",
       "       [ 3.00000000e+00,  8.00000000e+00,  6.00000000e+00,\n",
       "        -9.47439232e-01],\n",
       "       [ 3.00000000e+00,  8.00000000e+00,  6.00000000e+00,\n",
       "        -9.47439232e-01],\n",
       "       [ 3.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "        -7.24420522e-01],\n",
       "       [ 3.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "        -7.24420522e-01],\n",
       "       [ 9.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "         1.92186373e-01],\n",
       "       [ 9.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "         1.92186373e-01],\n",
       "       [ 2.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "         2.68999592e+00],\n",
       "       [ 8.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "         1.12886495e+00],\n",
       "       [ 5.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -3.87662271e-01],\n",
       "       [ 8.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "         5.04412566e-01],\n",
       "       [ 8.00000000e+00,  2.00000000e+01,  1.00000000e+00,\n",
       "         2.06554353e+00],\n",
       "       [ 5.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 2.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -9.67510916e-01],\n",
       "       [ 9.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "         6.60525662e-01],\n",
       "       [ 8.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -7.44492206e-01],\n",
       "       [ 9.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "         6.60525662e-01],\n",
       "       [ 2.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 5.00000000e+00,  2.00000000e+00,  6.00000000e+00,\n",
       "        -8.33699690e-01],\n",
       "       [ 4.00000000e+00,  2.00000000e+00,  6.00000000e+00,\n",
       "        -1.05671840e+00],\n",
       "       [ 4.00000000e+00,  1.50000000e+01,  6.00000000e+00,\n",
       "        -7.44492206e-01],\n",
       "       [ 4.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "        -7.44492206e-01],\n",
       "       [ 0.00000000e+00,  8.00000000e+00,  6.00000000e+00,\n",
       "         1.69884502e-01],\n",
       "       [ 4.00000000e+00,  4.00000000e+00,  6.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 4.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 4.00000000e+00,  4.00000000e+00,  6.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 0.00000000e+00,  9.00000000e+00,  3.00000000e+00,\n",
       "         1.37714053e-02],\n",
       "       [ 0.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -4.54567884e-01],\n",
       "       [ 0.00000000e+00,  2.00000000e+01,  1.00000000e+00,\n",
       "         3.25997598e-01],\n",
       "       [ 0.00000000e+00,  6.00000000e+00,  4.00000000e+00,\n",
       "        -6.77586594e-01],\n",
       "       [ 5.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -2.76152917e-01],\n",
       "       [ 1.10000000e+01,  1.00000000e+01,  4.00000000e+00,\n",
       "        -5.21473497e-01],\n",
       "       [ 6.00000000e+00,  1.70000000e+01,  5.00000000e+00,\n",
       "        -4.99171626e-01],\n",
       "       [ 7.00000000e+00,  6.00000000e+00,  4.00000000e+00,\n",
       "        -5.88379110e-01],\n",
       "       [ 9.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "         3.78278759e+00],\n",
       "       [ 7.00000000e+00,  1.40000000e+01,  0.00000000e+00,\n",
       "        -1.20039820e-01],\n",
       "       [ 2.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -2.76152917e-01],\n",
       "       [ 1.00000000e+00,  2.00000000e+01,  1.00000000e+00,\n",
       "         1.12886495e+00],\n",
       "       [ 0.00000000e+00,  1.90000000e+01,  6.00000000e+00,\n",
       "        -6.77586594e-01],\n",
       "       [ 0.00000000e+00,  4.00000000e+00,  6.00000000e+00,\n",
       "        -9.00605303e-01],\n",
       "       [ 0.00000000e+00,  1.80000000e+01,  4.00000000e+00,\n",
       "        -6.77586594e-01],\n",
       "       [ 0.00000000e+00,  6.00000000e+00,  4.00000000e+00,\n",
       "        -7.44492206e-01],\n",
       "       [ 1.10000000e+01,  1.80000000e+01,  4.00000000e+00,\n",
       "        -2.76152917e-01],\n",
       "       [ 7.00000000e+00,  4.00000000e+00,  6.00000000e+00,\n",
       "        -3.43058530e-01],\n",
       "       [ 7.00000000e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "        -4.32266013e-01],\n",
       "       [ 4.00000000e+00,  2.00000000e+00,  6.00000000e+00,\n",
       "        -6.10680981e-01],\n",
       "       [ 4.00000000e+00,  2.00000000e+00,  6.00000000e+00,\n",
       "        -1.05671840e+00],\n",
       "       [ 4.00000000e+00,  1.50000000e+01,  6.00000000e+00,\n",
       "        -5.88379110e-01],\n",
       "       [ 4.00000000e+00,  7.00000000e+00,  6.00000000e+00,\n",
       "        -9.00605303e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf['action_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42defc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rouds</th>\n",
       "      <th>n_actions</th>\n",
       "      <th>action</th>\n",
       "      <th>position</th>\n",
       "      <th>reward</th>\n",
       "      <th>pscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>80</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>80</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>80</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rouds  n_actions  action  position  reward  pscore\n",
       "0    10000         80      14         2       0  0.0125\n",
       "1    10000         80      14         2       0  0.0125\n",
       "2    10000         80      27         2       0  0.0125\n",
       "3    10000         80      48         1       0  0.0125\n",
       "4    10000         80      36         1       0  0.0125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"n_rouds\": bf[\"n_rounds\"],\n",
    "\"n_actions\": bf[\"n_actions\"],\n",
    "    \"action\": bf[\"action\"],\n",
    "    \"position\": bf[\"position\"],\n",
    "    \"reward\": bf[\"reward\"],\n",
    "    \"pscore\": bf[\"pscore\"],\n",
    "    # \"context\": bf[\"context\"],\n",
    "    # \"action_context\": bf[\"action_context\"]\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9608e800",
   "metadata": {},
   "source": [
    "# 2) Define evaluation policy = BTS with ZOZOTOWN prior\n",
    "The definition of BernoulliTS is here \n",
    "https://github.com/st-tech/zr-obp/blob/master/obp/policy/contextfree.py\n",
    "* Recall: Thompson Sampling assumes each action’s reward probability (CTR) follows a Beta(α, β) distribution.\n",
    "* α ≈ number of observed successes (clicks).\n",
    "* β ≈ number of observed failures (non-clicks).\n",
    "\n",
    "So for action 0,\n",
    "* alpha=47.0, beta=12198.0\n",
    "Prior CTR ≈ 47 / (47 + 12198) ≈ 0.0038."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccadcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliTS(n_actions=80, len_list=3, batch_size=1, random_state=123, alpha=[47.0, 8.0, 62.0, 142.0, 3.0, 14.0, 7.0, 857.0, 12.0, 15.0, 6.0, 100.0, 48.0, 23.0, 71.0, 61.0, 13.0, 16.0, 518.0, 30.0, 7.0, 4.0, 23.0, 8.0, 10.0, 11.0, 11.0, 18.0, 121.0, 11.0, 11.0, 10.0, 14.0, 9.0, 204.0, 58.0, 3.0, 19.0, 42.0, 1013.0, 2.0, 328.0, 15.0, 31.0, 14.0, 138.0, 45.0, 55.0, 23.0, 38.0, 10.0, 401.0, 52.0, 6.0, 3.0, 6.0, 5.0, 32.0, 35.0, 133.0, 52.0, 820.0, 43.0, 195.0, 8.0, 42.0, 40.0, 4.0, 32.0, 30.0, 9.0, 22.0, 6.0, 23.0, 5.0, 54.0, 8.0, 22.0, 65.0, 246.0], beta=[12198.0, 3566.0, 15993.0, 35522.0, 2367.0, 4609.0, 3171.0, 181745.0, 4372.0, 4951.0, 3100.0, 24665.0, 13210.0, 7061.0, 18061.0, 17449.0, 5644.0, 6787.0, 111326.0, 8776.0, 3334.0, 2271.0, 7389.0, 2659.0, 3665.0, 4724.0, 3561.0, 5085.0, 27407.0, 4601.0, 4756.0, 4120.0, 4736.0, 3788.0, 45292.0, 14719.0, 2189.0, 5589.0, 11995.0, 222255.0, 2308.0, 70034.0, 4801.0, 8274.0, 5421.0, 31912.0, 12213.0, 13576.0, 6230.0, 10382.0, 4141.0, 85731.0, 12811.0, 2707.0, 2250.0, 2668.0, 2886.0, 9581.0, 9465.0, 28336.0, 12062.0, 162793.0, 12107.0, 41240.0, 3162.0, 11604.0, 10818.0, 2923.0, 8897.0, 8654.0, 4000.0, 6580.0, 3174.0, 6766.0, 2602.0, 14506.0, 3968.0, 7523.0, 16532.0, 51964.0], is_zozotown_prior=True, campaign='all', policy_name='bts')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_e = BernoulliTS(\n",
    "    n_actions=ds.n_actions,\n",
    "    len_list=ds.len_list,\n",
    "    is_zozotown_prior=True,\n",
    "    campaign=\"all\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "pi_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dd71046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obp.policy.contextfree.BernoulliTS"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pi_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa029566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pi_e.alpha), len(pi_e.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae356584",
   "metadata": {},
   "source": [
    "# 3) Compute evaluation action distribution for each round (factorized by slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9323dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw action_dist shape: (10000, 80, 3)\n",
      "action_dist OK: (10000, 3, 80)\n"
     ]
    }
   ],
   "source": [
    "# after compute_batch_action_dist(...)\n",
    "print(\"raw action_dist shape:\", action_dist.shape)  # e.g., (10000, 80, 3)\n",
    "\n",
    "# 1) If it's 2D, tile across positions\n",
    "if action_dist.ndim == 2:  # (n_rounds, n_actions)\n",
    "    action_dist = np.repeat(action_dist[:, None, :], ds.len_list, axis=1)\n",
    "\n",
    "# 2) If it's 3D but axis order is (n_rounds, n_actions, len_list), swap to (n_rounds, len_list, n_actions)\n",
    "if action_dist.ndim == 3 and action_dist.shape[1] == ds.n_actions and action_dist.shape[2] == ds.len_list:\n",
    "    action_dist = np.swapaxes(action_dist, 1, 2)\n",
    "\n",
    "# final sanity checks\n",
    "assert action_dist.shape == (n, ds.len_list, ds.n_actions), action_dist.shape\n",
    "\n",
    "# normalize over the *action* axis (last axis) just in case\n",
    "sums = action_dist.sum(axis=2, keepdims=True)\n",
    "action_dist = action_dist / np.clip(sums, 1e-12, None)\n",
    "\n",
    "# verify each position’s probs sum to 1\n",
    "sums_check = action_dist.sum(axis=2)  # (n_rounds, len_list)\n",
    "assert np.allclose(sums_check, 1.0, atol=1e-6), (sums_check.min(), sums_check.max())\n",
    "print(\"action_dist OK:\", action_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c9a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 3, 80) dtype: float64\n",
      "nan?  False\n",
      "min/max: 1.0000000000000004e-05 0.24366000000000004\n",
      "sum range: 0.9999999999999999 1.0000000000000002\n",
      "neg? False | >1? False | NaN? False | sums!=1? False\n",
      "zero-sum slots: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"shape:\", action_dist.shape, \"dtype:\", action_dist.dtype)\n",
    "print(\"nan? \", np.isnan(action_dist).any())\n",
    "print(\"min/max:\", float(action_dist.min()), float(action_dist.max()))\n",
    "\n",
    "# per-(round,slot) sums should be exactly 1\n",
    "sums = action_dist.sum(axis=2)\n",
    "print(\"sum range:\", float(sums.min()), float(sums.max()))\n",
    "\n",
    "bad_neg   = (action_dist < 0).any()\n",
    "bad_gt1   = (action_dist > 1).any()\n",
    "bad_nan   = np.isnan(action_dist).any()\n",
    "bad_sum   = (~np.isclose(sums, 1.0, atol=1e-6)).any()\n",
    "\n",
    "print(\"neg?\", bad_neg, \"| >1?\", bad_gt1, \"| NaN?\", bad_nan, \"| sums!=1?\", bad_sum)\n",
    "\n",
    "# how many slots have sum==0 (totally invalid)\n",
    "zero_sum = (sums <= 0).sum()\n",
    "print(\"zero-sum slots:\", int(zero_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a8c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_dist_3d: (10000, 3, 80) sum range: 0.9999999999999998 1.0000000000000002\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`action_dist` must be a probability distribution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 2) Run OPE (pass the 3D array)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m ope \u001b[38;5;241m=\u001b[39m OffPolicyEvaluation(bandit_feedback\u001b[38;5;241m=\u001b[39mbf, ope_estimators\u001b[38;5;241m=\u001b[39m[IPW(), SNIPW()])\n\u001b[0;32m---> 41\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[43mope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_policy_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_dist_3d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 3) Report\u001b[39;00m\n\u001b[1;32m     44\u001b[0m logged \u001b[38;5;241m=\u001b[39m bf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda/envs/obp_replication/lib/python3.10/site-packages/obp/ope/meta.py:317\u001b[0m, in \u001b[0;36mOffPolicyEvaluation.estimate_policy_values\u001b[0;34m(self, action_dist, estimated_rewards_by_reg_model, estimated_pscore, estimated_importance_weights, action_embed, pi_b, p_e_a)\u001b[0m\n\u001b[1;32m    307\u001b[0m estimator_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_estimator_inputs(\n\u001b[1;32m    308\u001b[0m     action_dist\u001b[38;5;241m=\u001b[39maction_dist,\n\u001b[1;32m    309\u001b[0m     estimated_rewards_by_reg_model\u001b[38;5;241m=\u001b[39mestimated_rewards_by_reg_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m     p_e_a\u001b[38;5;241m=\u001b[39mp_e_a,\n\u001b[1;32m    315\u001b[0m )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator_name, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mope_estimators_\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 317\u001b[0m     policy_value_dict[estimator_name] \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_policy_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mestimator_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m policy_value_dict\n",
      "File \u001b[0;32m~/miniconda/envs/obp_replication/lib/python3.10/site-packages/obp/ope/estimators.py:391\u001b[0m, in \u001b[0;36mInverseProbabilityWeighting.estimate_policy_value\u001b[0;34m(self, reward, action, action_dist, pscore, position, estimated_pscore, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     check_array(array\u001b[38;5;241m=\u001b[39mpscore, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, expected_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    389\u001b[0m     pscore_ \u001b[38;5;241m=\u001b[39m pscore\n\u001b[0;32m--> 391\u001b[0m \u001b[43mcheck_ope_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpscore_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(action_dist\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/obp_replication/lib/python3.10/site-packages/obp/utils.py:351\u001b[0m, in \u001b[0;36mcheck_ope_inputs\u001b[0;34m(action_dist, position, action, reward, pscore, estimated_rewards_by_reg_model, estimated_importance_weights)\u001b[0m\n\u001b[1;32m    349\u001b[0m check_array(array\u001b[38;5;241m=\u001b[39maction_dist, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, expected_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(action_dist\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`action_dist` must be a probability distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# position\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: `action_dist` must be a probability distribution"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from obp.ope import OffPolicyEvaluation, InverseProbabilityWeighting as IPW, SelfNormalizedInverseProbabilityWeighting as SNIPW\n",
    "\n",
    "def ensure_3d_action_dist(ad, len_list, n_actions):\n",
    "    \"\"\"Return (n_rounds, len_list, n_actions) valid probs.\"\"\"\n",
    "    ad = np.asarray(ad, dtype=np.float64)\n",
    "\n",
    "    # (n, A) -> tile across positions\n",
    "    if ad.ndim == 2 and ad.shape[1] == n_actions:\n",
    "        ad = np.repeat(ad[:, None, :], len_list, axis=1)\n",
    "\n",
    "    # If axes are (n, A, L) -> swap to (n, L, A)\n",
    "    if ad.ndim == 3 and ad.shape[1] == n_actions and ad.shape[2] == len_list:\n",
    "        ad = np.swapaxes(ad, 1, 2)\n",
    "\n",
    "    # Final shape guard\n",
    "    assert ad.ndim == 3 and ad.shape[1] == len_list and ad.shape[2] == n_actions, f\"bad shape {ad.shape}\"\n",
    "\n",
    "    # Clean & renormalize over the action axis (last)\n",
    "    ad = np.nan_to_num(ad, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    ad = np.clip(ad, 0.0, None)\n",
    "    sums = ad.sum(axis=2, keepdims=True)\n",
    "    zero = sums <= 0\n",
    "    if np.any(zero):\n",
    "        # fill any degenerate slot with uniform\n",
    "        ad[zero.repeat(n_actions, axis=2)] = 1.0 / n_actions\n",
    "        sums = ad.sum(axis=2, keepdims=True)\n",
    "    ad /= sums\n",
    "    # sanity\n",
    "    sums_check = ad.sum(axis=2)\n",
    "    assert np.allclose(sums_check, 1.0, atol=1e-6), (sums_check.min(), sums_check.max())\n",
    "    return ad\n",
    "\n",
    "# 1) Make sure action_dist is valid 3D\n",
    "action_dist_3d = ensure_3d_action_dist(action_dist, ds.len_list, ds.n_actions)\n",
    "print(\"action_dist_3d:\", action_dist_3d.shape, \"sum range:\",\n",
    "      float(action_dist_3d.sum(axis=2).min()), float(action_dist_3d.sum(axis=2).max()))\n",
    "\n",
    "# 2) Run OPE (pass the 3D array)\n",
    "ope = OffPolicyEvaluation(bandit_feedback=bf, ope_estimators=[IPW(), SNIPW()])\n",
    "est = ope.estimate_policy_values(action_dist=action_dist_3d)\n",
    "\n",
    "# 3) Report\n",
    "logged = bf[\"reward\"].mean()\n",
    "ipw_val  = est[\"ipw\"]\n",
    "snipw_val = est[\"snipw\"]\n",
    "print(f\"Logged avg reward (Random/all): {logged:.6f}\")\n",
    "print(f\"IPW estimate for BTS:            {ipw_val:.6f}\")\n",
    "print(f\"SNIPW estimate for BTS:          {snipw_val:.6f}\")\n",
    "print(f\"Relative (IPW / logged):         {ipw_val/logged:.3f}x\")\n",
    "\n",
    "# 4) Optional importance-weight sanity (taken action at logged slot)\n",
    "row = np.arange(bf[\"n_rounds\"])\n",
    "pi_e_taken = action_dist_3d[row, bf[\"position\"], bf[\"action\"]]\n",
    "w = pi_e_taken / bf[\"pscore\"]\n",
    "print(\"Mean importance weight (≈1):\", w.mean())\n",
    "ess = (w.sum()**2) / (w**2).sum()\n",
    "print(f\"ESS: {ess:.0f} / {bf['n_rounds']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aaabf3",
   "metadata": {},
   "source": [
    "ope = OffPolicyEvaluation(bandit_feedback=bf, ope_estimators=[IPW(), SNIPW()])\n",
    "est = ope.estimate_policy_values(action_dist=action_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fda964",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obp_replication",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
