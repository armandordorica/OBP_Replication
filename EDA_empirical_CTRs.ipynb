{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83c0b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/01_quickstart.ipynb\n",
    "from obp.dataset import OpenBanditDataset\n",
    "from obp.policy import BernoulliTS\n",
    "from obp.ope import OffPolicyEvaluation, InverseProbabilityWeighting as IPW\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f60a1",
   "metadata": {},
   "source": [
    "### Load the logs from Zozotown\n",
    "For each visitor, the site showed 3 random items out of thousands (note that behavior policy selected is random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e9aa54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obp.dataset.real:When `data_path` is not given, this class downloads the small-sized version of Open Bandit Dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>position</th>\n",
       "      <th>reward</th>\n",
       "      <th>pscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      action  position  reward  pscore\n",
       "0         14         2       0  0.0125\n",
       "1         14         2       0  0.0125\n",
       "2         27         2       0  0.0125\n",
       "3         48         1       0  0.0125\n",
       "4         36         1       0  0.0125\n",
       "...      ...       ...     ...     ...\n",
       "9995       2         1       0  0.0125\n",
       "9996      45         1       0  0.0125\n",
       "9997      32         2       0  0.0125\n",
       "9998      13         1       0  0.0125\n",
       "9999      47         0       0  0.0125\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = OpenBanditDataset(behavior_policy=\"random\", campaign=\"all\")\n",
    "\n",
    "bf = ds.obtain_batch_bandit_feedback()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"action\": bf[\"action\"],\n",
    "    \"position\": bf[\"position\"],\n",
    "    \"reward\": bf[\"reward\"],\n",
    "    \"pscore\": bf[\"pscore\"],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3a56a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate average reward per action per position and pivot to wide format\n",
    "# avg_reward_per_action_position = df.groupby(['position', 'action'])['reward'].mean().reset_index()\n",
    "\n",
    "# # Pivot to have one row per action with separate columns for each position\n",
    "# avg_reward_pivot = avg_reward_per_action_position.pivot(index='action', columns='position', values='reward')\n",
    "\n",
    "# # Rename columns to have descriptive names\n",
    "# avg_reward_pivot.columns = [f'avg_reward_position_{int(pos)}' for pos in avg_reward_pivot.columns]\n",
    "\n",
    "# # Reset index to make action a regular column\n",
    "# avg_reward_pivot = avg_reward_pivot.reset_index()\n",
    "\n",
    "# # Fill NaN values with 0 or keep as NaN (depending on your preference)\n",
    "# # avg_reward_pivot = avg_reward_pivot.fillna(0)  # Uncomment if you want to fill NaN with 0\n",
    "\n",
    "# avg_reward_pivot['source'] = 'dataloader/random/all'\n",
    "\n",
    "# avg_reward_pivot.to_csv('empirical_ctr_dataloader_random_all.csv')\n",
    "\n",
    "# display(avg_reward_pivot.style.bar(align='mid', color=['red', 'lightgreen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a61a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obp.dataset.real:When `data_path` is not given, this class downloads the small-sized version of Open Bandit Dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded random/all dataset:\n",
      "  - Shape: (10000, 4)\n",
      "  - Unique actions: 80\n",
      "  - Overall CTR: 0.0038\n",
      "Saved results to: empirical_ctr_dataloader_random_all.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_empirical_ctr_by_position(behavior_policy=\"random\", campaign=\"all\", \n",
    "                                        fill_nan=False, save_csv=True, display_result=True,\n",
    "                                        include_counts=True):\n",
    "    \"\"\"\n",
    "    Calculate empirical CTR by action and position for a given behavior policy.\n",
    "    \n",
    "    Parameters:\n",
    "    - behavior_policy: str, behavior policy to analyze (e.g., \"random\", \"bts\")\n",
    "    - campaign: str, campaign to analyze (e.g., \"all\", \"men\", \"women\")\n",
    "    - fill_nan: bool, whether to fill NaN values with 0\n",
    "    - save_csv: bool, whether to save results to CSV\n",
    "    - display_result: bool, whether to display the styled results\n",
    "    - include_counts: bool, whether to include numerator and denominator columns\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.DataFrame: Pivoted CTR data with one row per action, including counts if requested\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    ds = OpenBanditDataset(behavior_policy=behavior_policy, campaign=campaign)\n",
    "    bf = ds.obtain_batch_bandit_feedback()\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        \"action\": bf[\"action\"],\n",
    "        \"position\": bf[\"position\"],\n",
    "        \"reward\": bf[\"reward\"],\n",
    "        \"pscore\": bf[\"pscore\"],\n",
    "    })\n",
    "    \n",
    "    print(f\"Loaded {behavior_policy}/{campaign} dataset:\")\n",
    "    print(f\"  - Shape: {df.shape}\")\n",
    "    print(f\"  - Unique actions: {df['action'].nunique()}\")\n",
    "    print(f\"  - Overall CTR: {df['reward'].mean():.4f}\")\n",
    "    \n",
    "    # Calculate statistics per action per position\n",
    "    stats_per_action_position = df.groupby(['position', 'action'])['reward'].agg([\n",
    "        'mean',  # Average (CTR)\n",
    "        'sum',   # Numerator (total clicks)\n",
    "        'count'  # Denominator (total impressions)\n",
    "    ]).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    stats_per_action_position.columns = ['position', 'action', 'avg_reward', 'sum_reward', 'count_reward']\n",
    "    \n",
    "    # Pivot average rewards to wide format\n",
    "    avg_reward_pivot = stats_per_action_position.pivot(index='action', columns='position', values='avg_reward')\n",
    "    avg_reward_pivot.columns = [f'avg_reward_position_{int(pos)}' for pos in avg_reward_pivot.columns]\n",
    "    avg_reward_pivot = avg_reward_pivot.reset_index()\n",
    "    \n",
    "    if include_counts:\n",
    "        # Pivot sum (numerator) to wide format\n",
    "        sum_reward_pivot = stats_per_action_position.pivot(index='action', columns='position', values='sum_reward')\n",
    "        sum_reward_pivot.columns = [f'sum_reward_position_{int(pos)}' for pos in sum_reward_pivot.columns]\n",
    "        sum_reward_pivot = sum_reward_pivot.reset_index()\n",
    "        \n",
    "        # Pivot count (denominator) to wide format  \n",
    "        count_reward_pivot = stats_per_action_position.pivot(index='action', columns='position', values='count_reward')\n",
    "        count_reward_pivot.columns = [f'count_position_{int(pos)}' for pos in count_reward_pivot.columns]\n",
    "        count_reward_pivot = count_reward_pivot.reset_index()\n",
    "        \n",
    "        # Merge all pivot tables\n",
    "        result_df = avg_reward_pivot.merge(sum_reward_pivot, on='action', how='outer')\n",
    "        result_df = result_df.merge(count_reward_pivot, on='action', how='outer')\n",
    "        \n",
    "        # Convert sum and count columns to integers (handling NaN values)\n",
    "        sum_cols = [col for col in result_df.columns if col.startswith('sum_reward_position_')]\n",
    "        count_cols = [col for col in result_df.columns if col.startswith('count_position_')]\n",
    "        \n",
    "        for col in sum_cols + count_cols:\n",
    "            result_df[col] = result_df[col].fillna(0).astype(int)\n",
    "    else:\n",
    "        result_df = avg_reward_pivot\n",
    "    \n",
    "    # Fill NaN values if requested\n",
    "    if fill_nan:\n",
    "        result_df = result_df.fillna(0)\n",
    "    \n",
    "    # Add source information\n",
    "    result_df['source'] = f'dataloader/{behavior_policy}/{campaign}'\n",
    "    \n",
    "    # Save to CSV if requested\n",
    "    if save_csv:\n",
    "        filename = f'empirical_ctr_dataloader_{behavior_policy}_{campaign}.csv'\n",
    "        result_df.to_csv(filename, index=False)\n",
    "        print(f\"Saved results to: {filename}\")\n",
    "    \n",
    "    # Display styled results if requested\n",
    "    if display_result:\n",
    "        print(f\"\\nEmpirical CTR by Action and Position ({behavior_policy}/{campaign}):\")\n",
    "        # Only style the average reward columns for the bar chart\n",
    "        avg_cols = [col for col in result_df.columns if col.startswith('avg_reward_position_')]\n",
    "        if avg_cols:\n",
    "            display(result_df.style.bar(subset=avg_cols, align='mid', color=['red', 'lightgreen']))\n",
    "        else:\n",
    "            display(result_df)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage with random policy (your original code) - now with counts\n",
    "random_ctr = calculate_empirical_ctr_by_position(\n",
    "    behavior_policy=\"random\", \n",
    "    campaign=\"all\",\n",
    "    fill_nan=False,\n",
    "    save_csv=True,\n",
    "    display_result=False,\n",
    "    include_counts=True  # Now includes numerator and denominator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "688d8710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obp.dataset.real:When `data_path` is not given, this class downloads the small-sized version of Open Bandit Dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bts/all dataset:\n",
      "  - Shape: (10000, 4)\n",
      "  - Unique actions: 80\n",
      "  - Overall CTR: 0.0042\n",
      "Saved results to: empirical_ctr_dataloader_bts_all.csv\n"
     ]
    }
   ],
   "source": [
    "bts_ctr = calculate_empirical_ctr_by_position(\n",
    "    behavior_policy=\"bts\", \n",
    "    campaign=\"all\",\n",
    "    fill_nan=False,\n",
    "    save_csv=True,\n",
    "    display_result=False,\n",
    "    include_counts=True  # Now includes numerator and denominator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d3c8c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CTR LIFT ANALYSIS: BTS vs Random\n",
      "============================================================\n",
      "Positions analyzed: [0, 1, 2]\n",
      "      Random CTR: 0.0038 (38 clicks / 10,000 impressions)\n",
      "         BTS CTR: 0.0042 (42 clicks / 10,000 impressions)\n",
      "Absolute Lift: +0.0004\n",
      "Relative Lift: +10.53%\n",
      "\n",
      "✅ BTS performs 10.53% better than Random\n"
     ]
    }
   ],
   "source": [
    "def compute_ctr_lift(baseline_ctr_df, treatment_ctr_df, baseline_name=\"Baseline\", treatment_name=\"Treatment\"):\n",
    "    \"\"\"\n",
    "    Compute CTR lift between two policies.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_ctr_df: DataFrame with CTR data for baseline policy (e.g., random)\n",
    "    - treatment_ctr_df: DataFrame with CTR data for treatment policy (e.g., BTS)\n",
    "    - baseline_name: Name of baseline policy for display\n",
    "    - treatment_name: Name of treatment policy for display\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary with lift metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find available positions dynamically\n",
    "    baseline_positions = set()\n",
    "    treatment_positions = set()\n",
    "    \n",
    "    for col in baseline_ctr_df.columns:\n",
    "        if col.startswith('sum_reward_position_'):\n",
    "            pos = int(col.split('_')[-1])\n",
    "            baseline_positions.add(pos)\n",
    "    \n",
    "    for col in treatment_ctr_df.columns:\n",
    "        if col.startswith('sum_reward_position_'):\n",
    "            pos = int(col.split('_')[-1])\n",
    "            treatment_positions.add(pos)\n",
    "    \n",
    "    # Use intersection of available positions\n",
    "    available_positions = sorted(baseline_positions.intersection(treatment_positions))\n",
    "    \n",
    "    baseline_total_clicks = 0\n",
    "    baseline_total_impressions = 0\n",
    "    treatment_total_clicks = 0\n",
    "    treatment_total_impressions = 0\n",
    "    \n",
    "    # Calculate totals across all available positions\n",
    "    for pos in available_positions:\n",
    "        sum_col = f'sum_reward_position_{pos}'\n",
    "        count_col = f'count_position_{pos}'\n",
    "        \n",
    "        if sum_col in baseline_ctr_df.columns and count_col in baseline_ctr_df.columns:\n",
    "            baseline_total_clicks += baseline_ctr_df[sum_col].sum()\n",
    "            baseline_total_impressions += baseline_ctr_df[count_col].sum()\n",
    "            \n",
    "        if sum_col in treatment_ctr_df.columns and count_col in treatment_ctr_df.columns:\n",
    "            treatment_total_clicks += treatment_ctr_df[sum_col].sum()\n",
    "            treatment_total_impressions += treatment_ctr_df[count_col].sum()\n",
    "    \n",
    "    # Calculate overall CTRs\n",
    "    baseline_overall_ctr = baseline_total_clicks / baseline_total_impressions if baseline_total_impressions > 0 else 0\n",
    "    treatment_overall_ctr = treatment_total_clicks / treatment_total_impressions if treatment_total_impressions > 0 else 0\n",
    "    \n",
    "    # Calculate lift metrics\n",
    "    absolute_lift = treatment_overall_ctr - baseline_overall_ctr\n",
    "    relative_lift = (treatment_overall_ctr / baseline_overall_ctr - 1) * 100 if baseline_overall_ctr > 0 else float('inf')\n",
    "    \n",
    "    results = {\n",
    "        'baseline_name': baseline_name,\n",
    "        'treatment_name': treatment_name,\n",
    "        'baseline_ctr': baseline_overall_ctr,\n",
    "        'treatment_ctr': treatment_overall_ctr,\n",
    "        'baseline_clicks': baseline_total_clicks,\n",
    "        'baseline_impressions': baseline_total_impressions,\n",
    "        'treatment_clicks': treatment_total_clicks,\n",
    "        'treatment_impressions': treatment_total_impressions,\n",
    "        'absolute_lift': absolute_lift,\n",
    "        'relative_lift_percent': relative_lift,\n",
    "        'available_positions': available_positions\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CTR LIFT ANALYSIS: {treatment_name} vs {baseline_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Positions analyzed: {available_positions}\")\n",
    "    print(f\"{baseline_name:>12} CTR: {baseline_overall_ctr:.4f} ({baseline_total_clicks:,} clicks / {baseline_total_impressions:,} impressions)\")\n",
    "    print(f\"{treatment_name:>12} CTR: {treatment_overall_ctr:.4f} ({treatment_total_clicks:,} clicks / {treatment_total_impressions:,} impressions)\")\n",
    "    print(f\"{'Absolute Lift':>12}: {absolute_lift:+.4f}\")\n",
    "    print(f\"{'Relative Lift':>12}: {relative_lift:+.2f}%\")\n",
    "    \n",
    "    if relative_lift > 0:\n",
    "        print(f\"\\n✅ {treatment_name} performs {relative_lift:.2f}% better than {baseline_name}\")\n",
    "    elif relative_lift < 0:\n",
    "        print(f\"\\n❌ {treatment_name} performs {abs(relative_lift):.2f}% worse than {baseline_name}\")\n",
    "    else:\n",
    "        print(f\"\\n➖ {treatment_name} and {baseline_name} have identical performance\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compute lift between Random and BTS\n",
    "lift_results = compute_ctr_lift(\n",
    "    baseline_ctr_df=random_ctr,\n",
    "    treatment_ctr_df=bts_ctr,\n",
    "    baseline_name=\"Random\",\n",
    "    treatment_name=\"BTS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_confidence_intervals(ctr_df, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Add confidence intervals to CTR dataframe using Wilson score interval.\n",
    "    \n",
    "    Parameters:\n",
    "    - ctr_df: DataFrame returned by calculate_empirical_ctr_by_position with include_counts=True\n",
    "    - confidence_level: float, confidence level (e.g., 0.95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.DataFrame: Original dataframe with added confidence interval columns\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    \n",
    "    result_df = ctr_df.copy()\n",
    "    \n",
    "    # Get z-score for confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # Find position columns\n",
    "    positions = []\n",
    "    for col in ctr_df.columns:\n",
    "        if col.startswith('avg_reward_position_'):\n",
    "            pos = col.split('_')[-1]\n",
    "            positions.append(pos)\n",
    "    \n",
    "    for pos in positions:\n",
    "        avg_col = f'avg_reward_position_{pos}'\n",
    "        count_col = f'count_position_{pos}'\n",
    "        sum_col = f'sum_reward_position_{pos}'\n",
    "        \n",
    "        if all(col in ctr_df.columns for col in [avg_col, count_col, sum_col]):\n",
    "            # Extract values\n",
    "            p = ctr_df[avg_col]  # proportion (CTR)\n",
    "            n = ctr_df[count_col]  # sample size\n",
    "            \n",
    "            # Wilson score interval (more accurate for small samples)\n",
    "            # Handle cases where n is 0 or NaN\n",
    "            mask = (n > 0) & (~pd.isna(n)) & (~pd.isna(p))\n",
    "            \n",
    "            # Initialize CI columns with NaN\n",
    "            ci_lower = pd.Series(np.nan, index=ctr_df.index)\n",
    "            ci_upper = pd.Series(np.nan, index=ctr_df.index)\n",
    "            \n",
    "            # Calculate CI only for valid observations\n",
    "            if mask.any():\n",
    "                p_valid = p[mask]\n",
    "                n_valid = n[mask]\n",
    "                \n",
    "                # Wilson score interval formula\n",
    "                denominator = 1 + (z**2 / n_valid)\n",
    "                center = (p_valid + (z**2 / (2 * n_valid))) / denominator\n",
    "                margin = (z / denominator) * np.sqrt((p_valid * (1 - p_valid) / n_valid) + (z**2 / (4 * n_valid**2)))\n",
    "                \n",
    "                ci_lower[mask] = center - margin\n",
    "                ci_upper[mask] = center + margin\n",
    "            \n",
    "            # Add CI columns to result\n",
    "            result_df[f'ci_lower_position_{pos}'] = ci_lower\n",
    "            result_df[f'ci_upper_position_{pos}'] = ci_upper\n",
    "            result_df[f'ci_width_position_{pos}'] = ci_upper - ci_lower\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage function\n",
    "def analyze_ctr_with_confidence_intervals(behavior_policy=\"random\", campaign=\"all\", confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Convenience function to get CTR data with confidence intervals.\n",
    "    \"\"\"\n",
    "    # Get CTR data with counts\n",
    "    ctr_data = calculate_empirical_ctr_by_position(\n",
    "        behavior_policy=behavior_policy,\n",
    "        campaign=campaign,\n",
    "        include_counts=True,\n",
    "        display_result=False\n",
    "    )\n",
    "    \n",
    "    # Add confidence intervals\n",
    "    ctr_with_ci = add_confidence_intervals(ctr_data, confidence_level=confidence_level)\n",
    "    \n",
    "    print(f\"\\nCTR Analysis with {confidence_level*100:.0f}% Confidence Intervals:\")\n",
    "    print(f\"Policy: {behavior_policy}, Campaign: {campaign}\")\n",
    "    \n",
    "    # Display summary\n",
    "    positions = [col.split('_')[-1] for col in ctr_data.columns if col.startswith('avg_reward_position_')]\n",
    "    for pos in positions:\n",
    "        avg_col = f'avg_reward_position_{pos}'\n",
    "        ci_lower_col = f'ci_lower_position_{pos}'\n",
    "        ci_upper_col = f'ci_upper_position_{pos}'\n",
    "        count_col = f'count_position_{pos}'\n",
    "        \n",
    "        valid_data = ctr_with_ci[~pd.isna(ctr_with_ci[avg_col])]\n",
    "        if not valid_data.empty:\n",
    "            avg_ctr = valid_data[avg_col].mean()\n",
    "            avg_count = valid_data[count_col].mean()\n",
    "            avg_ci_width = valid_data[f'ci_width_position_{pos}'].mean()\n",
    "            \n",
    "            print(f\"  Position {pos}: Avg CTR = {avg_ctr:.4f}, Avg Count = {avg_count:.1f}, Avg CI Width = {avg_ci_width:.4f}\")\n",
    "    \n",
    "    return ctr_with_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440661af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can easily analyze different behavior policies:\n",
    "\n",
    "# Bernoulli Thompson Sampling - with counts for confidence intervals\n",
    "bts_ctr = calculate_empirical_ctr_by_position(\n",
    "    behavior_policy=\"bts\", \n",
    "    campaign=\"all\",\n",
    "    fill_nan=False,\n",
    "    save_csv=True,\n",
    "    display_result=True,\n",
    "    include_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938839e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get CTR data with confidence intervals\n",
    "random_ctr_with_ci = analyze_ctr_with_confidence_intervals(\"random\", \"all\", confidence_level=0.95)\n",
    "\n",
    "# Display a few rows to see the structure\n",
    "print(\"\\nSample of CTR data with confidence intervals:\")\n",
    "display(random_ctr_with_ci.head())\n",
    "\n",
    "# You can also manually add confidence intervals to existing data\n",
    "if 'count_position_1' in bts_ctr.columns:\n",
    "    bts_ctr_with_ci = add_confidence_intervals(bts_ctr, confidence_level=0.95)\n",
    "    print(f\"\\nBTS CTR data now has confidence intervals. Shape: {bts_ctr_with_ci.shape}\")\n",
    "else:\n",
    "    print(\"\\nNote: Make sure to set include_counts=True to get confidence intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ctr_across_policies(policies=[\"random\", \"bts\"], campaign=\"all\"):\n",
    "    \"\"\"\n",
    "    Compare CTR across different behavior policies.\n",
    "    \n",
    "    Parameters:\n",
    "    - policies: list of behavior policies to compare\n",
    "    - campaign: campaign to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary with CTR dataframes for each policy\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Comparing CTR across policies: {', '.join(policies)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for policy in policies:\n",
    "        print(f\"\\n--- {policy.upper()} POLICY ---\")\n",
    "        try:\n",
    "            ctr_data = calculate_empirical_ctr_by_position(\n",
    "                behavior_policy=policy,\n",
    "                campaign=campaign,\n",
    "                display_result=False,\n",
    "                save_csv=True\n",
    "            )\n",
    "            results[policy] = ctr_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {policy}: {e}\")\n",
    "            results[policy] = None\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY COMPARISON\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for policy, data in results.items():\n",
    "        if data is not None:\n",
    "            overall_avg = data[['avg_reward_position_1', 'avg_reward_position_2', 'avg_reward_position_3']].mean(axis=1).mean()\n",
    "            actions_with_data = data.dropna(subset=['avg_reward_position_1', 'avg_reward_position_2', 'avg_reward_position_3'], how='all').shape[0]\n",
    "            print(f\"{policy:>10}: Overall avg CTR = {overall_avg:.4f}, Actions with data = {actions_with_data}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "policy_comparison = compare_ctr_across_policies([\"random\", \"bts\"])\n",
    "policy_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Ensure all 80 actions (0-79) are included even if they don't appear in data\n",
    "avg_reward_per_action_position_complete = df.groupby(['position', 'action'])['reward'].mean().reset_index()\n",
    "\n",
    "# Create a complete index of all action-position combinations\n",
    "all_actions = range(ds.n_actions)  # Assuming ds.n_actions = 80\n",
    "all_positions = df['position'].unique()\n",
    "\n",
    "# Create a complete DataFrame with all combinations\n",
    "import itertools\n",
    "all_combinations = pd.DataFrame(\n",
    "    list(itertools.product(all_positions, all_actions)), \n",
    "    columns=['position', 'action']\n",
    ")\n",
    "\n",
    "# Merge with actual data\n",
    "complete_data = all_combinations.merge(\n",
    "    avg_reward_per_action_position_complete, \n",
    "    on=['position', 'action'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Pivot to wide format\n",
    "avg_reward_pivot_complete = complete_data.pivot(index='action', columns='position', values='reward')\n",
    "\n",
    "# Rename columns\n",
    "avg_reward_pivot_complete.columns = [f'avg_reward_position_{int(pos)}' for pos in avg_reward_pivot_complete.columns]\n",
    "\n",
    "# Reset index\n",
    "avg_reward_pivot_complete = avg_reward_pivot_complete.reset_index()\n",
    "\n",
    "print(f\"Shape of complete pivot table: {avg_reward_pivot_complete.shape}\")\n",
    "print(f\"Number of unique actions: {avg_reward_pivot_complete['action'].nunique()}\")\n",
    "display(avg_reward_pivot_complete.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average reward per action, including all possible actions\n",
    "avg_reward_per_action = df.groupby(['action'])['reward'].agg(['mean', 'count']).reset_index()\n",
    "avg_reward_per_action.columns = ['action', 'avg_reward', 'num_observations']\n",
    "\n",
    "# Create a complete range of all possible actions (0 to max action)\n",
    "all_actions = pd.DataFrame({'action': range(ds.n_actions)})\n",
    "\n",
    "# Merge to include all actions, even those not in the data\n",
    "avg_reward_per_action_complete = all_actions.merge(avg_reward_per_action, on='action', how='left')\n",
    "\n",
    "# Mark actions with no data as NaN (not 0)\n",
    "avg_reward_per_action_complete['has_data'] = avg_reward_per_action_complete['num_observations'].notna()\n",
    "avg_reward_per_action_complete['avg_reward'] = avg_reward_per_action_complete['avg_reward'].fillna(0)\n",
    "avg_reward_per_action_complete['num_observations'] = avg_reward_per_action_complete['num_observations'].fillna(0).astype(int)\n",
    "\n",
    "avg_reward_per_action_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862681f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Sort by action to ensure proper ordering\n",
    "avg_reward_per_action_complete = avg_reward_per_action_complete.sort_values('action').reset_index(drop=True)\n",
    "\n",
    "# Add a label column to differentiate between zero CTR and no data\n",
    "avg_reward_per_action_complete['data_status'] = avg_reward_per_action_complete.apply(\n",
    "    lambda row: 'No Data' if not row['has_data'] else ('Zero CTR' if row['avg_reward'] == 0 else 'Has CTR'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Plot average reward per action with color coding\n",
    "fig = px.bar(avg_reward_per_action_complete, \n",
    "             x='action', \n",
    "             y='avg_reward',\n",
    "             color='data_status',\n",
    "             title='Average Reward per Action (All Actions Shown)',\n",
    "             labels={'action': 'Action ID', 'avg_reward': 'Average Reward', 'data_status': 'Data Status'},\n",
    "             height=500,\n",
    "             color_discrete_map={'Has CTR': '#636EFA', 'Zero CTR': '#EF553B', 'No Data': '#CCCCCC'},\n",
    "             hover_data=['num_observations'])\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.update_xaxes(type='linear', dtick=1)  # Ensure actions are shown in numeric order\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_action_position = df.groupby('action')['position'].nunique().reset_index()\n",
    "counts_by_action_position.columns = ['action', 'num_unique_positions']\n",
    "counts_by_action_position[counts_by_action_position['num_unique_positions'] <3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average CTR:\", bf[\"reward\"].mean())\n",
    "print(\"Unique items recommended:\", len(set(bf[\"action\"])))\n",
    "print(\"Position counts:\", pd.Series(bf[\"position\"]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_ctr = pd.DataFrame({\"pos\": bf[\"position\"], \"click\": bf[\"reward\"]}).groupby(\"pos\").mean()\n",
    "pos_ctr.plot(kind=\"bar\", legend=False, title=\"Click-through rate by slot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da64660",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08837b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluation policy distribution over actions per round (factorized by position)\n",
    "pi_e = BernoulliTS(\n",
    "    n_actions=ds.n_actions, len_list=ds.len_list,\n",
    "    is_zozotown_prior=True, campaign=\"all\", random_state=123\n",
    ")\n",
    "action_dist = pi_e.compute_batch_action_dist(\n",
    "    n_sim=100_000, n_rounds=bf[\"n_rounds\"]\n",
    ")\n",
    "\n",
    "ope = OffPolicyEvaluation(bandit_feedback=bf, ope_estimators=[IPW()])\n",
    "est = ope.estimate_policy_values(action_dist=action_dist)\n",
    "print(\"IPW estimate:\", est[\"ipw\"])\n",
    "print(\"Logged avg reward:\", bf[\"reward\"].mean())\n",
    "print(\"Relative (IPW/logged):\", est[\"ipw\"] / bf[\"reward\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65a866",
   "metadata": {},
   "source": [
    "### Making Sure the CTRs match using CSV vs OpenBanditDataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11550b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV (Random/all)\n",
    "csv = pd.read_csv(\"zr-obp/obd/random/all/all.csv\", index_col=0)\n",
    "csv[\"pos0\"] = csv[\"position\"] - 1\n",
    "ctr_csv = csv.groupby(\"pos0\")[\"click\"].mean().rename(\"ctr_csv\")\n",
    "\n",
    "# OBP loader (Random/all)\n",
    "ds = OpenBanditDataset(behavior_policy=\"random\", campaign=\"all\")\n",
    "bf = ds.obtain_batch_bandit_feedback()\n",
    "ctr_bf = (pd.DataFrame({\"pos0\": bf[\"position\"], \"click\": bf[\"reward\"]})\n",
    "          .groupby(\"pos0\")[\"click\"].mean().rename(\"ctr_bf\"))\n",
    "\n",
    "print(pd.concat([ctr_csv, ctr_bf], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d66d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015a479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
